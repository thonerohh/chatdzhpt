Python script to use chromedriver.exe with selenium and through urls.txt make automated tests for website availability and content load. Check every url and save as data.csv as content of head > title, head > meta:description, head > meta:keywords, body > h1, h2, h3, body > .shelf > a, body > .issue-card > a, body > .grid.products.tiles > a. Through testing each page collect via querySelctorAll('a').href's and add to the current set queue and save all found a's hrefs to another .txt splitted with new line as new_links.txt